[{"content":"Back in 2013, I was building a system to help with pediatric kidney transplant research while also trying to write a PhD at the same time. That split did not work out. I liked building the system and the team around it way more than writing papers and the dissertation work itself. Still, it took me a while though to actually acknowledge that. To allow myself to say: I like the one thing more than the original goal. But finally I did and decided to focus exactly on this: building tech, building teams, learning how to do it better and to do a lot of that.\nSo, I joined Thoughtworks. And it was amazing! I\u0026rsquo;ve learned a ton and had way more fun along the way than I ever thought possible. But after a while one thought started to keep me busy: How would it be to commit to building one thing, from the ground up - to own all the mistakes and successes, to see it really through. With time this notion of \u0026ldquo;ownership\u0026rdquo; got more and more important to me.\nSome time later, I had a chat with a friend. We talked about a company that he joined and the product they had in mind and it clicked 💡: Being a part of something that can truly make a positive impact and being able to have an impact on how it\u0026rsquo;s being built: with fun, empathy \u0026amp; focus. I couldn\u0026rsquo;t say no 😀 So now I\u0026rsquo;m at Gropyus 👷.\n","permalink":"/blog/a_change/","summary":"Back in 2013, I was building a system to help with pediatric kidney transplant research while also trying to write a PhD at the same time. That split did not work out. I liked building the system and the team around it way more than writing papers and the dissertation work itself. Still, it took me a while though to actually acknowledge that. To allow myself to say: I like the one thing more than the original goal.","title":"A change / next step"},{"content":"Java/JVM ecosystem is extremely mature and vast. It comes with a palette of production-ready choices for libraries solving problems that we face developing all kinds of services: be it from logging/metrics to async messaging or access to all the major sql and nosql data stores. Add the big talent pool (Java is very often used as the programming language used during CS-courses)[1] and it\u0026rsquo;s no wonder that this particular language and ecosystem is on the top or among the top 5 in the programming language statistics [2][3].\nHaving said that, I often feel that there is a certain fatigue when it comes to choice of the application framework. For me it seems that a lot of teams or even companies land on Spring without questioning if it\u0026rsquo;s actually the right tool for the particular task and what would be the alternatives. This is even more puzzling as microservices become a more and more popular architectural style and that IMHO changes a lot of the requirements one has for the app framework as e.g. memory footprint and startup time become way more relevant.\nThis post is by no means intended to say Spring is a wrong choice or something along those lines. It\u0026rsquo;s more a call-out to look at other alternatives in that space that may be just smaller, simpler and offer a more light-weight approach. And there is something to be told about the more light-weight approach too: It\u0026rsquo;s been a while that I\u0026rsquo;ve seen a team that truly understood all the batteries that are included in Spring and did not struggle from time to time with some of the concepts that are in play. Hence, I wanted to take a closer look at some of the other options that are around the block by implementing a small service, that is not so far off a real scenario: consume messages from a queue, aggregate certain information exposing it via an REST endpoint and implement it using spring and others. All code and exact numbers can be found in this repo. This post will be growing as I will be adding the result of my little experiment one by one over time. In the end it will be a summary of what I\u0026rsquo;ve discovered along the way and what you may also find interesting.\nSo let\u0026rsquo;s look at the options? All the options that I ended up taking into consideration address the changed nature of the systems that we write by switching from reflection-based approach to a compile-time based approach. They also support creation of native images thanks to GraalVM which makes the result both impressively fast to start and also very small. The tradeoff here is the duration of the compilation time. I will be looking at:\nMicronaut Quarkus Helidion If I managed to at least catch your interest, then watch the repo and this space for updates.\n","permalink":"/blog/java-frameworks/","summary":"Java/JVM ecosystem is extremely mature and vast. It comes with a palette of production-ready choices for libraries solving problems that we face developing all kinds of services: be it from logging/metrics to async messaging or access to all the major sql and nosql data stores. Add the big talent pool (Java is very often used as the programming language used during CS-courses)[1] and it\u0026rsquo;s no wonder that this particular language and ecosystem is on the top or among the top 5 in the programming language statistics [2][3].","title":"Java Frameworks in 2020 ?"},{"content":"I ordered the UHK with the linux layout as I thought that I will be moving towards a linux laptop as the main driver for my work. Somehow this didn\u0026rsquo;t happen :confused: and therefore I ended up using the UHK with a Mackbook Pro. Thus, I changed few settings and love my setup even more. UHK is really a spectacular keyboard.\nI quickly decided to just align the Fn, Ctrl, Option and Cmd key with the mac layout so that my mussle memory doesn\u0026rsquo;t suffer too much. This also made me fell in love with the UHK agent: It\u0026rsquo;s just so easy to remap the keys to your liking.\nWhile at it, I also changed the default Mouse key to become my Ctrl (cause I alwas been remaping the Caps key to have that behaviour) and decided to allocate the Mouse key behavoiur to the Space key on the edge of the keyboard as I have not been using this key at all.\nTo customize my internal keyboard layout on the Mac, I\u0026rsquo;ve been using karabiner-essentials for a while now, With it, I made my CAPS become ESC while pressed alone and Ctrl if pressed with in combination with other key. Since the switch to the UHK and my Mod+Mouse being ESC, I missed this on when working on the go only with the internal keyboard, therefore I now use Cmd + Caps for ESC on my internal keyboard too, as it\u0026rsquo;s the same movement for my fingers. To be able to do so, I wrote a little complex modification for karabiner-elements:\n","permalink":"/blog/uhk_setup/","summary":"I ordered the UHK with the linux layout as I thought that I will be moving towards a linux laptop as the main driver for my work. Somehow this didn\u0026rsquo;t happen :confused: and therefore I ended up using the UHK with a Mackbook Pro. Thus, I changed few settings and love my setup even more. UHK is really a spectacular keyboard.\nI quickly decided to just align the Fn, Ctrl, Option and Cmd key with the mac layout so that my mussle memory doesn\u0026rsquo;t suffer too much.","title":"My first UHK layout"},{"content":"I figured it\u0026rsquo;s time to write up the quickest guide about using the yubikey as the source of your ssh key. This assumes that:\nYou have a yubikey and it\u0026rsquo;s in your usb port You\u0026rsquo;ve configured gpg on you machine (I\u0026rsquo;m running gpg (GnuPG) 2.2.7) You\u0026rsquo;re using the gpg-agent with enabled ssh support Here are the steps:\ngpg --card-edit \u0026gt; admin \u0026gt; generate \u0026gt; [enter the requested PIN] \u0026gt; quit And now you\u0026rsquo;re done. You can check if the new ssh key get pulled correctly from your yubikey typing:\nssh-add -L And you should see something like:\nssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC2ooHO4NuRkjkOQ6zpl/P+RQwRibWd2EZStK61IX2RksD8m2PQKA4rpoYlbwR8tHqJYp+9hF3630ZhDBLqaN6wnLOzJ9tdAFg2QkR7uw/TlWh3/3kuDjzF8GatYIvfvnbtlX0FtVuz+rmUAeUswYpvRQKA5feX5Tf9M56IhttRtFbXZjNz5BNy8qkXD9FOTX4Ym0Zidgn6tl9EKKH4ctvK1/wTF4oSHEfyVwpKLqn/FI+0DIDi5Lx8cpFLnB4nJqj1WFe8o86yRVNWq5PehOJR3qSpllfx3fheUXePRNPrvYGyO5Ch9aikzuPoLZh4oq/TTqkfjcZLQvTv1Ai+qk8J cardno:000605308805 Now you can use this key e.g for as your github key and whenever your push/pull/clone you will need to enter the yubikey into your device.\n","permalink":"/blog/sshkey_yubikey/","summary":"I figured it\u0026rsquo;s time to write up the quickest guide about using the yubikey as the source of your ssh key. This assumes that:\nYou have a yubikey and it\u0026rsquo;s in your usb port You\u0026rsquo;ve configured gpg on you machine (I\u0026rsquo;m running gpg (GnuPG) 2.2.7) You\u0026rsquo;re using the gpg-agent with enabled ssh support Here are the steps:\ngpg --card-edit \u0026gt; admin \u0026gt; generate \u0026gt; [enter the requested PIN] \u0026gt; quit And now you\u0026rsquo;re done.","title":"Using your yubikey as ssh key provider / Quick(est) guide"},{"content":"As you can see looking at the frequency of my posts, I\u0026rsquo;m more of an occasional writer. Therefore whenever I drag myself in front of my notebook, to write something up I\u0026rsquo;m feeling like sharing, I should really not have any reason to do something else instead. Sadly, although I was really happy with my octopress setup, more than once I found myself fighting the currently installed ruby versions and some conflicts with the gems that octopress was requiring.\nIn the quest of solving the problem once and for all, I decided to look at hugo that is as simple in usage as octopress and has the benefit of golang\u0026rsquo;s self-contaied binaries, that don\u0026rsquo;t depend on any runtime. And yes, hugo\u0026rsquo;s speed is impressive :dash: It probably doesn\u0026rsquo;t matter for my little blog, nevertheless it\u0026rsquo;s nice to have an instant live-reload whenever I work on a new post, or just play with the current design.\nThe migration from octopress was also very straightforward. Thanks to this little migration tool: octohug.\nBottom line: If you\u0026rsquo;re in the market for a new static web page generation tool, I strongly suggest hugo!\n","permalink":"/blog/why-hugo/","summary":"As you can see looking at the frequency of my posts, I\u0026rsquo;m more of an occasional writer. Therefore whenever I drag myself in front of my notebook, to write something up I\u0026rsquo;m feeling like sharing, I should really not have any reason to do something else instead. Sadly, although I was really happy with my octopress setup, more than once I found myself fighting the currently installed ruby versions and some conflicts with the gems that octopress was requiring.","title":"why hugo?"},{"content":"A while ago I wrote a ThoughtWorks insights post about the Backends for frontends pattern and the story behind its adaption at SoundCloud. It generated interesting discussions and resulted also in some further content and I thought it would be good to have a place with links to all this resources for the future reference.\nBFF @ SoundCloud - the original post talking about the pattern and journey towards it BFF pattern definition - comprehensive pattern definition Moving to Microservices at SoundCloud - Software Engineering Daily podcast - a podcast talking about microservices in gerneral, SoundCloud\u0026rsquo;s journey towards this style of architecture and usage of BFFs BFF @ SoundCloud (podcast) - an interview about UI composition in a microservices world in general and the BFF pattern ","permalink":"/blog/2016/02/22/bff/","summary":"A while ago I wrote a ThoughtWorks insights post about the Backends for frontends pattern and the story behind its adaption at SoundCloud. It generated interesting discussions and resulted also in some further content and I thought it would be good to have a place with links to all this resources for the future reference.\nBFF @ SoundCloud - the original post talking about the pattern and journey towards it BFF pattern definition - comprehensive pattern definition Moving to Microservices at SoundCloud - Software Engineering Daily podcast - a podcast talking about microservices in gerneral, SoundCloud\u0026rsquo;s journey towards this style of architecture and usage of BFFs BFF @ SoundCloud (podcast) - an interview about UI composition in a microservices world in general and the BFF pattern ","title":"bff"},{"content":" After we managed to set up our basic web application, let\u0026rsquo;s get our hands dirty writing some code. And as we want to do it in a test-driven manner (TDD), we need a proper test setup. This piece is all about our initial test pyramid. Test, what? Yes, pyramid:\nAt the base of the test automation pyramid is unit testing. Unit testing should be the foundation of a solid test automation strategy and as such represents the largest part of the pyramid. (\u0026hellip;) Automated user interface testing is placed at the top of the test automation pyramid because we want to do as little of it as possible. (\u0026hellip;) Testing through the user interface like this is expensive and should be minimized. Although there are many test cases that need to be invoked, not all need to be run through the user interface. And this is where the service layer of the test automation pyramid comes in. - Mike Cohn https://www.mountaingoatsoftware.com/blog/the-forgotten-layer-of-the-test-automation-pyramid\nDepending on your personal style (look at this post by Martin Fowler for more details around different flavours of unit testing) and probably also the task at hand, you will either be starting with a unit test or acceptance/functional test. The rest of this post will show you how to set up each kind of test and give you a brief description of what we mean by saying unit, integration and functional test. I will also describe our gulp setup.\nUnit test In JavaScript and node.js world your are spoiled for choices in regards to your unit tests libraries and runners: Jasmine, Mocha and friends, just pick one. We decided to go with Jasmine, in which a test looks like this:\n/* jshint node: true */ /* global describe, beforeEach, afterEach, it, jasmine, expect */ \u0026#39;use strict\u0026#39;; describe(\u0026#39;exractParticipant\u0026#39;, function () { var extractParticipant; var validRequestData = { body: { firstname: \u0026#39;Mark\u0026#39;, lastname: \u0026#39;Mueller\u0026#39;, email: \u0026#39;m.mueller@example.com\u0026#39; } }; beforeEach(function () { extractParticipant= require(\u0026#39;../routes/registration.js\u0026#39;).extractParticipant }); it(\u0026#39;should read firstname from the request body\u0026#39;, function() { expect(extractParticipant(validRequestData).firstname).toBe(\u0026#39;Mark\u0026#39;); }); it(\u0026#39;should throw an error if no firstname can be found\u0026#39;, function () { function callWithNoFirstname() { extractParticipant({body: {}}); } expect(callWithNoFirstname).toThrow(); }); } Here we are verifying the behavior of the extractParticipant() function which given a request body returns a specific JS object. We can use multiple describe calls, or even nested describe calls to cluster the tested functionality. Each it call corresponds with a specific behaviour we want to verify. Jasmine provides matchers and spies to simplify our testing: Just look at the reference to see what\u0026rsquo;s possible. Generally it\u0026rsquo;s a good practice to verify one specific aspect per test. Any other recommendations, you ask {%gemoji sunglasses%} A good unit test is:\nfast: All the unit tests will be executed very often, therefore it\u0026rsquo;s necessarry that their execution happens in ms atomic: The unit tests should be independant from one-another, so that you can run them parallel. This means that they should not relay on any side effects (data modifications done by other tests etc.). It\u0026rsquo;s also way easier to reason why a certain test is red, if all you need to care about is only the scope of that particular test. As usual Martin Fowler wrote a nice bliki about unit tests.\nIntegration test As the name already states, an integration test verifies the behaviour of a group of components of our software acting together. Look at the following test, which checks the intgeration between a service and the database:\n\u0026#39;use strict\u0026#39;; /* jshint node: true */ /* jshint esnext: true */ /* global describe, beforeEach, afterAll, it, jasmine, expect */ describe(\u0026#39;participants service\u0026#39;, function () { const participants = require(\u0026#39;../../service/participants\u0026#39;); var pg = require(\u0026#39;pg\u0026#39;); beforeEach(function (done) { var connectionString = process.env.SNAP_DB_PG_URL || \u0026#34;tcp://vagrant@localhost/pace\u0026#34;; var jasmineDone = done; pg.connect(connectionString, function (err, client, done) { client.query(\u0026#39;delete from participants\u0026#39;, function () { done(); jasmineDone(); }); } ); }); afterAll(function(done) { pg.end(); done(); }); it(\u0026#39;should store and read participants\u0026#39;, function (done) { var aParticipant = { firstname: \u0026#39;Hertha\u0026#39;, lastname: \u0026#39;Mustermann\u0026#39;, email: \u0026#39;h.mustermann@example.com\u0026#39; }; participants.save(aParticipant) .then(participants.getAll) .then(function (data) { expect(data.length).toBe(1); expect(data[0].firstname).toBe(aParticipant.firstname); expect(data[0].lastname).toBe(aParticipant.lastname); expect(data[0].email).toBe(aParticipant.email); done(); }); }); }); The integration test is similiar to the unit one (it\u0026rsquo;s also based on jasmine), but instead of mocking our dependencies we use the real implementation (here the pg PostgreSQL client) and verify the integration of both components. In this particular example, we store a participant and expect that if we call the getAll function, it will be returned in the correct form. As the test will actually store objects in the dabase, we need to assure that before we execute the test, the database is cleared. This is done in the beforeEach method. You may ask \u0026lsquo;why before the test and not afterwards\u0026rsquo;: In case of an error, we will still have the possibility to check the state of the database.\nAs we need to connect to the database and assure a particular state before each test run, those tests will always be slower than the unit ones. Therefore we should try to test only the integrational aspects in them and everything else on the unit level. In the end we are not interested in a test suite for a 3rd party component, but only a verification of the fact that our usage of it is correct.\nFunctional test Whenever we test the system as a whole, we talk about functional tests. Typically those tests go against an outer-most interface of our app, often the UI. In our case we will interact with pace via its web page. To do that, we use WebDriverIO on top of selenium and a headless browser called phantomjs. This combination offers an easy to use API for browser-interaction.\n/* jshint node: true */ /* global describe, beforeEach, afterEach, it, jasmine, expect */ \u0026#39;use strict\u0026#39;; describe(\u0026#39;regisitration journey\u0026#39;, function () { var client; var paceUrl = process.env.PACE_URL || \u0026#39;http://localhost:3000/\u0026#39;; var originalTimeout; beforeEach(function () { var webdriverio = require(\u0026#39;webdriverio\u0026#39;); var options = { desiredCapabilities: { browserName: \u0026#39;phantomjs\u0026#39; } }; client = webdriverio.remote(options); originalTimeout = jasmine.DEFAULT_TIMEOUT_INTERVAL; jasmine.DEFAULT_TIMEOUT_INTERVAL = 10000; }); afterEach(function () { jasmine.DEFAULT_TIMEOUT_INTERVAL = originalTimeout; }); it(\u0026#39;allows to register via the registration page\u0026#39;, function (done) { client.init() .url(paceUrl) .click(\u0026#39;a#registration\u0026#39;) .setValue(\u0026#39;input#firstname\u0026#39;, \u0026#39;Max\u0026#39;) .setValue(\u0026#39;input#lastname\u0026#39;, \u0026#39;Mustermann\u0026#39;) .setValue(\u0026#39;input#email\u0026#39;, \u0026#39;max@example.com\u0026#39;) .setValue(\u0026#39;input#gender\u0026#39;, \u0026#39;Unicorn\u0026#39;) .click(\u0026#39;button#submit\u0026#39;) .isVisible(\u0026#39;div.thanks\u0026#39;) .then(function (isVisible) { expect(isVisible).toBe(true); done(); }) .end(); }); }); First we need to setup the webdriver client to use the proper pace base url and browser. We also change the default jasmine timeout for async tests, as in general the browser based interactions tend to take more time. After that it is pretty straightforward: We click on a link, type into input fields, submit the form and verify that we land on the success page (look at webdriverio API for all the different interactions one can trigger). This is the happy path of our registration journey and as the functional test are the most expensive ones (in regards to the execution time), we will try to stick only to happy-path testing on this level.\nTest execution Ok, so how can you run all the tests in a convenient way? Pace uses gulp to build and automate a lot of stuff. Here are the important commands and convention:\nAll tests (specs) should be places in the /spec directory All integration tests must have \u0026lsquo;IT\u0026rsquo; in their filename All functional tests must have \u0026lsquo;Journey\u0026rsquo; in their filename gulp test - runs all the unit tests gulp test-integration - runs all the integration tests, depends on existing database gulp test-functional - runs all functional tests, depends on installed selenium-server and drivers To simplify the setup of a dev box, pace offers one simple command:\ngulp dev-setup - prepares the vagrant box with the databse, installs all dependencies for selenium and executes the database migrations ","permalink":"/blog/2015/10/10/express-testing/","summary":"After we managed to set up our basic web application, let\u0026rsquo;s get our hands dirty writing some code. And as we want to do it in a test-driven manner (TDD), we need a proper test setup. This piece is all about our initial test pyramid. Test, what? Yes, pyramid:\nAt the base of the test automation pyramid is unit testing. Unit testing should be the foundation of a solid test automation strategy and as such represents the largest part of the pyramid.","title":"express testing"},{"content":"Together with few friends we started building pace - a web application for organizing and managing running events \u0026amp; competitions. We are a colorful bunch of people with different backgrounds, therefore we wanted to choose an approachable tech stack, as some of us wants also to learn one or two things about JavaScript, web applications or programming in general.\nAnd then, somebody suggested to write one thing or two, about our technology decisions and accompany it with some HowTo information. So here we are.\nThis is the first post out of the pace series. We will take a look at how to quickly bootstrap a new express.js application and what is acctually happening during that process.\nFirst things first: node.js \u0026amp; express.js Node.js® is a platform built on Chrome\u0026rsquo;s JavaScript runtime for easily building fast, scalable network applications. Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient, perfect for data-intensive real-time applications that run across distributed devices. - Nodejs.org https://nodejs.org\nProbably also due to the popularity of JavaScript node quickly spread all around the web and is nowadays widely used and has an impressive ecosystem of additional libraries/modules (just take a look at npm package manager).\nexpress.js is one of many web frameworks based on node, but seems also to be one of the most popular ones. What is a web framework you ask:\nA web application framework is a software framework that is designed to support the development of dynamic websites, web applications, web services and web resources. The framework aims to alleviate the overhead associated with common activities performed in web development. For example, many frameworks provide libraries for database access, templating frameworks and session management, and they often promote code reuse - http://localhost:1313/post/2016/02/22/bff/\nHow to bootstrap a web app \u0026amp; what happens Assuming you have node already installed on your machine (if not look at here)\nnpm install express-generator -g express myWebApp cd myWebApp npm install npm start What happened you ask? So first we globally installed express-generator (it will be now available to you via express cmd). Then we made it bootstrap for us an app called myWebApp. This resulted in the following:\n/tmp|⇒ express myWebApp create : myWebApp create : myWebApp/package.json create : myWebApp/app.js create : myWebApp/public create : myWebApp/public/javascripts create : myWebApp/public/images create : myWebApp/routes create : myWebApp/routes/index.js create : myWebApp/routes/users.js create : myWebApp/public/stylesheets create : myWebApp/public/stylesheets/style.css create : myWebApp/views create : myWebApp/views/index.jade create : myWebApp/views/layout.jade create : myWebApp/views/error.jade create : myWebApp/bin create : myWebApp/bin/www install dependencies: $ cd myWebApp \u0026amp;\u0026amp; npm install run the app: $ DEBUG=myWebApp ./bin/www The generator created for us a new directory which contains all the needed files the web application consists of:\npackage.json -\u0026gt; definition of our node dependencies and some node configuration app.js -\u0026gt; the main entry point into the application public -\u0026gt; contains all public assets whic will be exposed to the public routes -\u0026gt; contains the definitions of our routes (as ourDomain/index or ourDomain/somethingDifferent) views -\u0026gt; contains our templates (more about this in future posts) bin/www -\u0026gt; executable application (if you run npm start this will be started) The execution of npm install in app\u0026rsquo;s directory, installs all the dependencies defined in the package.json file. Those dependencies will be installed only locally in the node_modules directory. After this step we are ready to go and able to run npm start which should result in this:\nmyWebApp|⇒ npm start \u0026gt; myWebApp@0.0.1 start /private/tmp/myWebApp \u0026gt; node ./bin/www GET / 200 305ms - 170b GET / 200 34ms - 170b GET /stylesheets/style.css 200 4ms - 110b GET / 304 25ms GET /stylesheets/style.css 304 1ms You can see, that I opened http://localhost:3000 in the browser and express served me the index page with the 200 code (you can also see that I refreshed the page and got 304 NOT MODIFIED). Everything works also as expected {%gemoji +1%}\nWhy? How? Let\u0026rsquo;s take a quick look at the following:\napp.js\nvar routes = require(\u0026#39;./routes/index\u0026#39;); app.use(\u0026#39;/\u0026#39;, routes) This is only a part of the app.js file but shows the wiring of our default root to the index.js file shown below. BTW: you can also see how to load dependencies/modules for our code via the require function (if you want to read more about that, here is a nice write-up)\nroutes/index.js:\nvar express = require(\u0026#39;express\u0026#39;); var router = express.Router(); /* GET home page. */ router.get(\u0026#39;/\u0026#39;, function(req, res) { title = \u0026#34;bootstraping a node dot js webapp\u0026#34; }); module.exports = router; The index.js uses express\u0026rsquo; router and wires request for / to the function responding with a rendered index.jade template, to which it passes a variable called title. If you never used jade, don\u0026rsquo;t worry, is a pretty simple HTML template engine. Look at the following: index.jade:\nextends layout block content h1= title p Welcome to #{title} Jade enables template composition. In here we extend layout.jade which defines the general page structure. If other template defines a block called content it will be then injected at the corresponding place. layout.jade:\ndoctype html html head title= title link(rel=\u0026#39;stylesheet\u0026#39;, href=\u0026#39;/stylesheets/style.css\u0026#39;) body block content Jade is indentation aware, meaning that the above example results in the following:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Express\u0026lt;/title\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;/stylesheets/style.css\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Express\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Welcome to Express\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Now you have seen all the parts making the browser render the most basic page of all time :sunglasses:\nNext post out of the pace series, will actually explain how to start working on the functionality we need. Right now you can start to play around with the data which is passed by the index.js to the index.jade template and how the template uses it. Have fun!\n","permalink":"/blog/2015/08/04/bootstraping-a-node-dot-js-webapp/","summary":"Together with few friends we started building pace - a web application for organizing and managing running events \u0026amp; competitions. We are a colorful bunch of people with different backgrounds, therefore we wanted to choose an approachable tech stack, as some of us wants also to learn one or two things about JavaScript, web applications or programming in general.\nAnd then, somebody suggested to write one thing or two, about our technology decisions and accompany it with some HowTo information.","title":"bootstraping a node.js webapp"},{"content":"During my last four projects or so, the teams I worked with were always using GO.CD as the CD tool of their choosing. Although the pipeline state visualisation GO.CD comes with is quite nice, it still doesn\u0026rsquo;t cut it as a proper, obvious build monitor enabling everybody in the team to quickly recognize what is the pipeline status.\nBurstah in action Therefore first cidar, a simple sinatra based build monitor, has been born. I quickly discovered that sinatra and especially the nokogiri dependency, doesn\u0026rsquo;t make it easy to use e.g. a Raspberry Pi as the monitor hardware. So, having the liberty, I decided to re-implement everything in JavaScript using node.js \u0026amp; express. Burstah , my second attempt at the ultimative build monitor, has been born :grin:\nAll the necessary information how to use, install or contribute can be found in Burstah\u0026rsquo;s readme.\nCurrently Burstah has following features:\nPolling for the cctray.xml to recognize the pipelines and their status Grabbing the commit details directly out of the GO.CD and presenting them Providing an animation when the build is running Supporting emojis in the commit messages :thumbsup: If you have any wishes or issues, just write stuff down on the github issues page.\n","permalink":"/blog/2015/06/27/build-monitors/","summary":"During my last four projects or so, the teams I worked with were always using GO.CD as the CD tool of their choosing. Although the pipeline state visualisation GO.CD comes with is quite nice, it still doesn\u0026rsquo;t cut it as a proper, obvious build monitor enabling everybody in the team to quickly recognize what is the pipeline status.\nBurstah in action Therefore first cidar, a simple sinatra based build monitor, has been born.","title":"build monitors"},{"content":"Last Thursday I was a part of the Scoopcamp hackathon and it was so great that I just couldn\u0026rsquo;t resist to write down some of my thoughts about it. Our team ThoughtWorks and friends a colorful mix of journalists, students and developers had a rough idea for a modern - more agile - journalism, where the journalist reporting about an ongoing event writes the background story and live updates from his perspective, but can also incorporate content written by the readers who create their own streams representing their own take on the particular event. Being able to see which stream/entry is getting most likes (=feedback), he/she can quickly react and focus on the currently favorite perspective. During a quick brainstorming we came up with the name: LiquidPub (for liquid publishing) and started defining the first user stories. Our app To be able to deliver something within less than a day of coding, we went with Ruby on Rails. This gave me the opportunity to finally try out Rails and learn it a bit by pairing with some experienced Ruby/Rails devs. The application itself has been deployed on heroku and being ThoughtWorks we built and deployed it after each push to our github repo using snap-ci - continuous delivery FTW!\nYou can see the result here.\nTech stack Ruby/Rails + slim (as the templating engine) + Foundation CSS lib (for a responsive client) PostgreSQL Some stats 4 dev pairs and 1 designer implemented 27 user stories in 6 iterations I arrived at 8:45 and left around 00:30 (true hackathon sprit! ;)) 91 builds / 145 commits Wrap-up + My take on Rails A day before the hackathon, I got the message that we will do it using Ruby on Rails - so I did not really have a lot of time to look into it. But that was actually no problem at all, as I paired with another guy who had some rails experience. Although I heard it often, I was still amazed how quickly one can set up a CRUD application with it. There is of course a lot of magic happening in the background and when you have some more complicated use cases, you really need to look deeper into the rails guide or other documentation. My pair and myself had some issues trying to integrate a WYSIWYG editor which was working in the development mode but not in the production mode due to some assets processing problems. This was the only problem we could not solve quickly. For templates we used slim which is definitely nice, but takes some time getting used to. Otherwise Rails provides as I already expected a very nice developer experience. As I am taking a deeper look into Play2.0 now, I can try to write the same application to be able to compare the development speed and experience of both frameworks. A blog post will follow. This hackathon was really a great opportunity to have fun and meet new people and try out new technologies. I really look forward to another event like this!\n","permalink":"/blog/2013/09/14/scoopcamp-hackathon/","summary":"Last Thursday I was a part of the Scoopcamp hackathon and it was so great that I just couldn\u0026rsquo;t resist to write down some of my thoughts about it. Our team ThoughtWorks and friends a colorful mix of journalists, students and developers had a rough idea for a modern - more agile - journalism, where the journalist reporting about an ongoing event writes the background story and live updates from his perspective, but can also incorporate content written by the readers who create their own streams representing their own take on the particular event.","title":"scoopcamp hackathon"},{"content":"Back in 2009 I became the job to design and start realizing a quite large web application for a health care research project. I took some time, sat down and thought about the technology stack, I would like to use to build it. As we wanted to have an RIA and I already had some experience with GWT, we quickly decided to use it. Since then four years have passed and we are about to release the 2.0 version of our system. During this time, the whole team learned a lot about GWT, its advantages and also some disadvantages, and I thought it would be useful to write some of them up. This part is about the status quo, in the second part I will try to write about a GWT setup I would go for, when starting the project today - so if you have any hints in this regard, please feel free to leave a comment, I would definitely appreciate it!\n1. Client setup Around the same time, as I started to draw the first diagrams of the inner life of our web app, Ray Ryan gave a talk at the IO conference about the best practices for GWT app architecture, mentioning the model view presenter, the usage of an event bus for components communication and the command pattern for dispatching the GWT-RPC calls to the server. Shortly after I discovered the gwt-presenter and the gwt-dispatch libraries, offering an easy way to build an GWT app based on the principles from Ray\u0026rsquo;s talk. I also found a very detailed blog post explaining how everything works together.\nMVP with EventBus and Dispatcher At this point we defined one Presenter for all the entities, we wanted to made accessible on the client, and each presenter defined his own Display interface which then was implemented by the View class. The instantiation of all presenters and views has been managed by gin - a dependency injection framework for the client side. The code looked more or less like this:\nPresenter \u0026amp; Display:\npublic class HistoryPresenter extends WidgetPresenter\u0026lt;HistoryPresenter.Display\u0026gt; implements PresentsDTO\u0026lt;HistoryDTO\u0026gt; { public interface Display extends WidgetDisplay, Resettable, Editable { HasText getPrimaryDisease(); HasText getPrimaryDiagnosis(); HasValue\u0026lt;Date\u0026gt; getPrimaryDiseaseStart(); HasValue\u0026lt;String\u0026gt; getHypertension(); // (...) and some more stuff here } private HistoryDTO currentDTO; private final DispatchAsync dispatcher; @Inject public HistoryPresenter(final Display display, final EventBus eventBus, final DispatchAsync dispatcher) { super(display, eventBus); bind(); } @Override protected void onBind() { // Add handlers to the event bus if needed } @Override public void resetUI() { currentDTO = null; display.resetUI(); } @Override public HistoryDTO getDTO() { syncDTO(); return currentDTO; } @Override public void syncDTO() { // create new DTO object with the content from the display } @Override public void showDTO(HistoryDTO dto) { // refresh the display with the data from the DTO } @Override public void setEditable(boolean value) { display.setEditable(value); } @Override protected void onRevealDisplay() { // React on place request e.g use the dispatcher to load the data from the server } } In the gwt-presenter class hierarchy there was no possibility to define the model class the presenter will be responsible for. For that reason we introduced a PresentDTO\u0026lt;T\u0026gt; and PresentDTOs\u0026lt;T\u0026gt; interfaces to ensure the existence of T getDTO() etc. methods. The view classes are quite straightforward, the only difference is that back in 2009 ui:binder was not really there, therefore the gwt-presenter had no direct support for it. But switching to the declarative layout definition was indeed very easy - each view defines its own *.ui.xml file and the asWidget() method just returns the result of the uiBinder.createAndBindUi() call. As you can see in the code below we introduced also a WidgetsManager class which is a convinient way to managed all the widgets the view is defining (offering a general setEditable() method and taking care of the validation visualization).\nView:\npublic class HistoryView implements Display { interface HistoryViewUiBinder extends UiBinder\u0026lt;LayoutPanel, HistoryView\u0026gt; {} private static HistoryViewUiBinder uiBinder = GWT.create(HistoryViewUiBinder.class); @UiField LabeledSuggestBox renalDisease; @UiField DateBox renalDiseaseStart; @UiField TextArea renalDiseaseText; @UiField ValueListBox hypertension; private final WidgetsManager widgetsManager; private final LayoutPanel content; @Inject public HistoryView(WidgetsManager widgetsManager, final RegisterConstants c) { this.widgetsManager = widgetsManager; content = uiBinder.createAndBindUi(this); content.setTitle(c.historyTab()); //Registering the widgets within the widget mgr. widgetsManager.registerWidgets( new String[] {\u0026#34;primaryDiseaseGroup\u0026#34;, \u0026#34;primaryDiseaseDiagnosis\u0026#34;, \u0026#34;primaryDiseaseStart\u0026#34;}, new Widget[] { renalDisease, renalDiseaseText, renalDiseaseStart}); widgetsManager.configureValidation(HistoryDTO.class); } @Override public Widget asWidget() { return content; } @Override public HasText getPrimaryDiagnosis() { return renalDiseaseText; } @Override public HasText getPrimaryDisease() { return renalDisease; } @Override public HasValue\u0026lt;Date\u0026gt; getPrimaryDiseaseStart() { return renalDiseaseStart; } } To ensure a loosely coupled client we try to communicate between the presenters only via the EventBus or PlaceRequests, so if a new part of the UI should be rendered, a new place event needs to be fired.\n2. Client - server communication The client - server communication is based fully on the GWT-RPC mechanism. As mentioned above we are using the gwt-dispatch library meaning that for every request, we have a command object, result object and a server side handler. It is a bit verbose, but in the end it is also a very simple pattern and every new dev introduced to our team grasps it very quickly. The implementation of the client-side caching is easily done, as you just need to compare the command object which should be executed and if one of them has been already seen, then you can serve the already received result saving you one round-trip.\nTo execute a command a corresponding object just needs to be passed to the dispatcher which is a singleton on the client and gets injected to every presenter that should be able to trigger the communication. In most of the cases the result of a command (or to use gwt-dispatch terminology: an action) contains a DTO object which is then shown by the presenter. On the server side we are using JPA \u0026amp; Hibernate so obviously we need to take care of the server entity to DTO conversion. Although some libraries exists for this purpose (e.g gilead), in our specific setting we decided to implement it ourself which was actually a straightforward task when using the reflection API and sticking to a well defined class hierarchy of our own. DTO We also use the JSR303 annotations for validation of the entities and are able to push the constraint violations back to the client where they will be assigned to the specific widgets by our WidgetsManager - here we are just using a simple convention of associating the input widgets with same names as the property paths in the entities.\n3. Testing the client One of the main advantages of doing MVP is the separation of the business logic (sitting in the presenter) from the actual UI components (being a part of the view) resulting in the ability of writing normal, fast unit test (normal, meaning not using the GWTTestCase) and mocking the views. Nevertheless in our project we use selenium as the main way to assure the correct functionality of our client. As using the normal selenium recorder is not an option with GWT due to the element ids changing during each compile process, we tried to get our selenium tests (written in java as normal unit tests) as independent as it only can be from the layout definition itself (trying not to use exact XPath etc.). Our client is very data input heavy, so we have a lot of input components to test. When we test if the entities get created in a correct way, we just access all visible input components of a certain type, populate them with a random content (which we then store for later comparison), trigger the save action and reload the UI to verify if the same components holds still the same data. Thus, we don\u0026rsquo;t have to update the tests if our data definition changes and we have introduced some new input components. The test will also work if the layout of the UI changes either on purpose, because we rearranged it, or when a new GWT version switch to a different HTML representation for some standard widgets.\nGetting certain elements from selenium driver:\nprotected static ArrayList\u0026lt;WebElement\u0026gt; getVisibleElements(String tagName, final String classString) { List\u0026lt;WebElement\u0026gt; elements = driver.findElements(By.tagName(tagName)); return Lists.newArrayList(Collections2.filter(elements, new Predicate\u0026lt;WebElement\u0026gt;() { @Override public boolean apply(@Nullable WebElement input) { boolean b = false; try { String classAttribute = input.getAttribute(\u0026#34;class\u0026#34;); b = input.isDisplayed() \u0026amp;\u0026amp; classAttribute != null \u0026amp;\u0026amp; classAttribute.contains(classString); } catch (StaleElementReferenceException e) { // Ignoring stale element } return b; } })); } 4. Issues We are quite happy how things are working now, but there is room for improvement:\nThe compile time during development: trying to change something in the client code in a iterative manner using the standard DevMode is very frustrating as it takes just too much time. SuperDevMode improved a lot our situation but we still have the problem of having the server and client side in one maven project - changing the server-side code means a mvn clean -DskipTests tomcat7:run-war and this means basically an \u0026ldquo;espresso\u0026rdquo; break. The size of the client: our *.cache.js file is currently 6.1MB (we use the gwtquery and gwt-chosen libs which are quite large) We will definitely try to introduce some code splitting in the future release, to load only as much as we need and not everything from the beginning. Execution time of the selenium tests: our current selenium suite takes a bit over 3 hours to run on our CI server. And although we could, we don\u0026rsquo;t have enough of the presenter unit tests to have a sufficient coverage letting us sleep well at night. Here probably a wrong choice have been made: concentrating to much on the selenium tests and trying to go for a very exhaustive test suite, instead of implementing a good amount of unit tests for the presenters and a simpler selenium suite for the main work flows in the application. ","permalink":"/blog/2013/06/15/gwt-part-i/","summary":"\u003cp\u003eBack in 2009 I became the job to design and start realizing a quite large web application for a health care research project. I took some time, sat down and thought about the technology stack, I would like to use to build it. As we wanted to have an RIA and I already had some experience with GWT, we quickly decided to use it. Since then four years have passed and we are about to release the 2.0 version of our system. During this time, the whole team learned a lot about GWT, its advantages and also some disadvantages, and I thought it would be useful to write some of them up. This part is about the \u003cstrong\u003estatus quo\u003c/strong\u003e, in the second part I will try to write about a GWT setup I would go for, when starting the project today - so if you have any hints in this regard, please feel free to leave a comment, I would definitely appreciate it!\u003c/p\u003e","title":"gwt part i"},{"content":"There\u0026rsquo;s nothing like this moment, when you have a big smile on your face, because you\u0026rsquo;re just stunned how well things are working and how simple the set-up process was. Octopress is just amazing. Period. If you haven\u0026rsquo;t heard about it and you\u0026rsquo;re thinking to start a blog or migrate one, then you should definitely check it out. To put it simple:\nOctopress is a framework designed by Brandon Mathis for Jekyll, the blog aware static site generator powering Github Pages. To start blogging with Jekyll, you have to write your own HTML templates, CSS, Javascripts and set up your configuration. But with Octopress All of that is already taken care of. Simply clone or fork Octopress, install dependencies and the theme, and you\u0026rsquo;re set. - Brandon Mathis http://octopress.org/blog/2011/07/23/octopress-20-surfaces/\nIt took me just few hours from having the idea: Today is the day to start my own blog to actually having it hosted on github. And the experience itself (checking out the octopress repo, configuring, building and deploying to github) was really simple. Thumbs up for the good documentation!\nMy setup octopress is publishing directly to my github user page. Therefore the access is fairly simple and I can use my blog to link to other stuff, I have on github or somewhere else like e.g. slides to my talks. I decided against using the default theme and went with a clean and responsive one called the whitespace. There are many, many others so everyone should be able to find something suiting own needs. A list with some of the themes available: 3rd-Party-Octopress-Themes During the set-up phase I had only one ubuntu-related (using the 13.04) hickup. When executing the bundle install I got an missing dependency error, so after googling for like a minute, I found a simple solution: just execute sudo apt-get install ruby1.9.1-full and everything will work as described in octopress docs. As I\u0026rsquo;m a zsh and oh-my-zsh user, I run also into the rake new_post[title] execution problem. A solution for it was also easily found: just add alias rake=\u0026ldquo;noglob rake\u0026rdquo; to your ~/.zshrc. To be able to see, if anybody actually reads this stuff, I activated the support for google analytics in the _config.yml file. I also activated disqus to support comments. Although I\u0026rsquo;ve never heard about it, it makes a very nice impression and as everything till now, was very easy to set-up (create an account, get unique id and put it into the _config.yml file). I deactivated all the discovery stuff from disqus though, as I\u0026rsquo;m not interested in monetizing anything here. If you read it till now, you may be asking yourself\nOK, yet another possibility to create a blog. So what. Why bother with all this stuff when one can just use blogger or wordpress.com.\nMy answer:\nKiller features \u0026amp; the work-flow Everything is hosted on github within my repository and I have control over all the files etc. To create a new blog post you just type rake new_post[\u0026lsquo;some title\u0026rsquo;] and open the created file to edit the content. Everything will be written in markdown (+1), so I\u0026rsquo;m using sublime as my editor and the distraction free mode when writing\u0026hellip; When you work on a new post or a change then you can tweak and test everything on your local machine under localhost:4000 with each change made automatically visible thanks to rake watch and rake preview Everything is manged by git, so you can work on posts in branches etc. When you\u0026rsquo;re done, you just hit rake generate and rake deploy and the new stuff will be pushed to github. ","permalink":"/blog/2013/05/14/setting-up-dot-dot-dot/","summary":"There\u0026rsquo;s nothing like this moment, when you have a big smile on your face, because you\u0026rsquo;re just stunned how well things are working and how simple the set-up process was. Octopress is just amazing. Period. If you haven\u0026rsquo;t heard about it and you\u0026rsquo;re thinking to start a blog or migrate one, then you should definitely check it out. To put it simple:\nOctopress is a framework designed by Brandon Mathis for Jekyll, the blog aware static site generator powering Github Pages.","title":"setting up ..."},{"content":"I had this idea to create my own blog since like forever but always convinced myself that it will be either too time consuming or all the topics I would like to write about, are already well described, so what\u0026rsquo;s the point \u0026hellip;\nBut then, I had also too many moments, when I thought - wait, you already had this problem/issue/idea\u0026hellip; What was the solution? Where did you find it?\nSo today, I finally decided to create my own blog - mainly as a reference for future me. I will write about the technology, I\u0026rsquo;m currently working with or interested in and from time to time maybe about some general stuff, I would like to talk about.\nAs I have no experience whatsoever in this domain (blog writing), I will try to push myself and write one post per month. Fingers crossed, that I\u0026rsquo;ll find the time for it \u0026hellip;\n","permalink":"/blog/2013/05/09/hello-world/","summary":"I had this idea to create my own blog since like forever but always convinced myself that it will be either too time consuming or all the topics I would like to write about, are already well described, so what\u0026rsquo;s the point \u0026hellip;\nBut then, I had also too many moments, when I thought - wait, you already had this problem/issue/idea\u0026hellip; What was the solution? Where did you find it?","title":"hello world"},{"content":"My name is Lukasz (he/him) and I really like creating products together with awesome teams. The roles that I play vary: from a dev, to a tech lead, to sombody trying to aling multiple teams going in the same direction. Whenever I can, I get my hands dirty with Java, Kotlin and JavaScript with a proper amount of terraform for the infrastructure. Ex-Thoughtworks, currently building things at air up 💦‍️.\nThis is a personal weblog. The opinions expressed here represent my own and not those of my employer.\nMy public key fingerprint 43F9 3BC4 8717 CED6 9B74 E40D 1274 8A7B CA91 C14C\n-----BEGIN PGP PUBLIC KEY BLOCK----- mQENBFhunMQBCAC9yN37HHCr/yEcO0XrfwH1WlMnwjAeV/Bh2UZChlsG7cOFBNHB eQwZ4j2aHxamd4rlpQX2dXCE69hfq1ktDOw2uazb2As2zPyg/DNiDBpoz42qnw5a 98WlZxpEyqsn6A+QDNPqG7K1eECRGV6mI28OUH209uZvnl6EjMtasuNvSx4p9nfL 3CZLcH+/NLT16YpJxMcBa7POFcWSL8N+fBuIEAZAQcxuNDxP+Ac2Ma4bVuFmkn2V MsWozLXwMnb4vRRGp7jhtP23MpyVBUt73L2SLy6a3beN2qvv1Qt3pA8vlU8pBXX+ 7rGZtKNqOktyAHnUdEihzUrnJfAUYleXcbknABEBAAG0OEx1a2FzeiBQbG90bmlj a2kgKFBlcnNvbmFsIE1haWwpIDxsLnBsb3RuaWNraUBnbWFpbC5jb20+iQE3BBMB CgAhBQJYbpzEAhsDBQsJCAcDBRUKCQgLBRYCAwEAAh4BAheAAAoJEBJ0invKkcFM iY8H/27ZhYD39WYnq0IS0ItMAMZdl38XKnafHnsafwHWThxTElhWvdDlXQOE9qlT qSckOr1wiVg377EoOix9og6p+djxkeLHupd4CQC3aHmWYqJaev17j1SSzgAayTRs ItQqEpq73tLSCxbwdiYlABfegcUyRsI+6rPICkcQGYzDt2d8YAOIVhVzjrmqkxaF 2E+WVoW7FvMztMYnMwH8oR+sU8f18LBchjN713BAckqLpM/ih9xo3l7TCmqmLtGL lPM4TuusTnamFgosAfUh6kFvbpAPN1/x6fqbkA1satn8yLf002AccSptFuMmiE1+ CG9MHS6M5h4krx6J1qTiBEiL5Y25AQ0EWG6cxAEIAMP4faAdZR6PP3zwsVeXyejC v5EKWhdZp9BmX+ANcRw2yuJUgo6Hipn375FBAAnEw7SSrwEIbuHaN368DMJ86iRm GR6KaFFrJZH+r7C2gZufCKY7fZe6ftiFWSPb863GLpGLpQ0uraDYhtOI93qMmykY ABMQPnlBmsxBfD0yLevjnMyLXeMZznHg11kDFV3hq08ZxtseKxJuc2ShtyMhiEBZ 5yM36F6Cbyp7X7htJnT4rapUcpRfTWPeCWYvQ7cDfERyNfKqlUEb4flWxi+on+hE WxLsonpvVFD3ntaP/lgvVXmqrJ4NArsORiOiwlQ0OiBnC5FkCMFwTowkGPSmskkA EQEAAYkBHwQYAQoACQUCWG6cxAIbDAAKCRASdIp7ypHBTC02CACE+ZbMGB1rnx2o dxqvJ1gVbcOC67ZoAXkYAmRxneyQgVR1gvfTY52CckOLi0CdsJS72Ob/geAYvBod BlTwhLVrvCtVl/6xCuzjSRmVeUSsgqT0LRKqY5ZYhJr80FlB52y755VoiWyc2HBw DZ7D5BhhlkZCU1A15CThxa9rsEZ/dp4tuYoKyDWfxlxBqTa1RYwF4LrfM0uvvjUi gGp26EfHaU/pucN98lXZvo4qTjqz5+yysTJXBDZrzIDrTFAsiyOMW3sR3vgkQYHv HrhB+rs1dKQV1Qg3wLKV2riHV+AHs9GI68eGrySPo00WNF7Aihvv+92VqnbKg1TS bplKPcxguQENBFhunfUBCACrgjYU/5bcB0TRX1dYLH1Tvq0de9wre0V71BEDPOoc DcjTdsk+WveTyc7ed6/6zJZeOkV28BkB2CrMyX7Z7TljIJtdohEo33CJ30e7JWr2 vcDsUvKbPOR2T2lPVehggJYlm53Do0afVxuX/j91Rw7HtIInpNZLPTtxsvhY/FFN 4rzcZguF9WHrsJ7MZxr2ManOGS3zAhnhFL0aEqme37v813xykOnnKU+YHPzPkdBZ v8C0nxy2fp/+AqwVTFBfk6WAm0t6jVSBBmiEmG0rtFAF3XWjM2kIM0key1GIdxvA uHLy+5frdXbj+GIiDylVzxI1Bkag+lRXoWNCwM/klZFdABEBAAGJAR8EGAEKAAkF AlhunfUCGyAACgkQEnSKe8qRwUycCwf/V+93vBELNDEAAcKk6OTd4SI2WgsrZTw1 OpE5GT3t/BgBp5IIk/tr4mJUb+O0ojl6uKJqfxXDjv4UPd2sT+A2Ew/20K1FBkuD Z6EPXZqX9NoTzdshT9vz7pbpf3mRwERsMgWccTOaNJEjAnRK2q8rajxMgfrYRFBy A9o/G9joWka4lYFNaeBWONZ56arjFvK3yvpi8hr+z8b6HFgr+1xPVGp8Ht1XXyr4 5LsCEZfnGzUcM1LxwAnjbH7LgXK0g1VER+GBKjSYX1G375hPBTurk/6rk+npehnm /kKZ+ndcAfpBPumi55LRHEsLOiP1x3GQlhBGnVbJaYLfyzHGgKQFQg== =BaNU -----END PGP PUBLIC KEY BLOCK----- ","permalink":"/about/","summary":"My name is Lukasz (he/him) and I really like creating products together with awesome teams. The roles that I play vary: from a dev, to a tech lead, to sombody trying to aling multiple teams going in the same direction. Whenever I can, I get my hands dirty with Java, Kotlin and JavaScript with a proper amount of terraform for the infrastructure. Ex-Thoughtworks, currently building things at air up 💦‍️.","title":""}]